
## Scaling distributed work RavenDB

[Distributed Deep Dive]:(#clustering-deep-dive)

In the previous chapter, we went over how RavenDB clusters and database groups work, we looked at the nitty gritty details, such as conflicts
and change vectors and how a cluster can handle failover and recovery. But we haven't actually talked about how to actually make use of a cluster.
This is primarily what we'll cover in this chapter. How to properly utilize your RavenDB cluster to best effect.

We'll cover how to grow your cluster to include a large number of nodes and how to host a _lot_ of databases in the clsuter, how we can automatically
have the cluster adjust the nodes a database reside on to ensure a minimum number of replicas and how we can deploy RavenDB in a geo distributed 
environment.

But first, we need to go back a bit and discuss the distributed mechanims in RavenDB, the cluster and the database group. The separation RavenDB makes between 
the cluster and the database group can be artifical. If you are running a single database on all your nodes, you usually
will not make any distinction between the cluster as a whole and the database group. This distinction starts to become a lot more important if you are working
in a system that utilizes many databases.

The simplest example for such a system is a micro service architecture. Each micro service in your system have its own database group that is running on the 
cluster, and you can define the number of nodes each database group will run on. This tend to be easier to manage, deploy and work with then having a separate
cluster per micro service. 

Other examples where you'll have multiple databases is for multi tenancy, where each tenant gets their own separate database. This make it very easy to deal
with tenant separation and you can adjust the number of nodes per tenant easily. This approach will also allow you to scale your system easily. As you have 
more tenants, you can just add more machines to the cluster and spread the load among them. 

That said, note that there is a certain cost for running each database instance, and that it is usually easier for RavenDB to have a single large database then
_many_ small ones. The general rule of thumb is that you shouldn't host more than a hundred or so active databases per machine.

### Growing your cluster

RavenDB is using Raft as the underlying consensus protocol for managing the cluster. The [Raft Paper](https://raft.github.io/raft.pdf) is a truly impressive 
reading, mostly because the paper manage to make one of the hardest tasks in distributed programming _understandable_. I highly recommend reading it even if
you never intend to dig into the details of how RavenDB or other distributed system does their magic. 

The simplest way to explain how it works is that the cluster make decisions based on majority confirmation. That does great injustice to both the algorithm and
the paper, but it simplify things and allow us to reason about them without deviating _too_ much from what is really going on. Majority confirmation is defined
as having a particular value on `N/2+1` of the nodes, using integer math and assuming that `N` is the number of nodes. In other words, if your cluster size is
3, then a majority would be 2 and any value that was confirmed by any two nodes is considerred committed.

Table 7.1 shows the majority for several common cluster size. Note that even numbers have the same majority as the odd number preceding them. Because of that,
you'll typically have an odd number of nodes in your cluster. 

| Cluster size | Majority |
|--------------|----------|
|            2 |        2 |
|            3 |        2 |
|            4 |        3 |
|            5 |        3 |
|            7 |        4 |
|            9 |        5 |
|           15 |        8 |
|           21 |       11 |
|           51 |       26 |

Table: Majories for different sized cluster

This majority behavior has a few very interesting implications that you need to consider. First, and quite obvious, if we have a failure condition that 
took out more than half of our cluster, the cluster as a whole will not be able to make any decisions (even while individial database instances will operate
normally). In a cluster of 5 nodes, if there aren't any 3 nodes that can communicate with each other, there is no way to reach any decision. 

On the other hand, the more nodes there are in your cluster, the more network traffic you need to make to reach any decision. In patalogical cases, such as a 
cluster size of 51, you'll need to contact at least 26 servers to reach any decision. That is going to impose a high latency requirement on anything that 
the cluster is doing. 

In practice, you very rarely grow the cluster beyond seven members or so. The cost of doing that is usually too high. At that point, you will either setup 
multiple independent clusters or use a different method. The cluster size we mentioned so far is for voting members in the cluster, but the cluster doesn't
have to contain only voting members. We can just add nodes to the cluster as watchers.

These nodes do not take part in the majority calculations and are only there to watch what is going on in the cluster. As far as RavenDB is concerned, they are
full blown members in the cluster, they can be assigned databases and work to be done, but we aren't going to include them in the hot path of making decisions 
in the cluster.

Using this approach, you can decide that three or five nodes in your cluster are the voting members and all the rest are just watchers. This gives us the ability to 
make decisions with a majority of only three nodes while the actual size of the cluster can be much higher. Of course, if a majority of the the voting members of
the cluster are unable to talk to one another (because they are down, the network failed, etc) then the cluster as a whole will not be available. 

> **What are cluster operations?**
>
> We have talked about cluster being down a lot, actually a lot more then most clusters _are_ down. A cluster being down means that database operations continue
> normally for databases, but we can't perform any cluster operation. What are all those cluster operations?
>
> Basically, anything that requires us to coordinate between multiple nodes is a cluster operation. A non exhuastive list^[The full list can be found in the online
> documentation] include creating and deleting databases, creating and deleting indexes and transformers, handling subscriptions and ETL processes and completing a 
> backup^[Backups _will_ happen on their regular schedule when the cluster is down, but they fail to be reported to the cluster and may run again after the clsuter
> recovered.].
>
> In all those cases, those are operations that we need a majority in the cluster to proccess. The underlying logic behind all of those operations is that they are
> all things that aren't generally user facing, so even in such an event, you'll be able to continue serving requests and operate normally as far as the external
> world is concerned while your operations are bringing up the failed nodes.

Figure 7.1 shows a cluster using three member nodes and two watchers. Node E is the leader and it is managing all of the nodes. Creating a database on this cluster
will cause it to allocate database instances to both member nodes and watchers node, but the cluster leaders can only be nodes A, B or E. If two of them are down
then the cluster as a whole is also down and you'll not be able to perform cluster operations (but your databases will function normally otherwise.)

![A cluster with members and watchers](./Ch07/img01.png)

Given that a cluster being unavailable doesn't usually impact ongoing database operations, the actual topology at scale is something that the operations team
need to consider. A single large cluster is usually easier to manage and the cluster can add as many watchers as you need to handle the load you are going to 
put on it. The databases themselves do not care what node they run on, whetever it is a voting member or just a watcher. And the cluster can manage database 
instance assignment across all machines with ease. 

### Mutliple datacenters and geo distribution

It is easy to reason about RavenDB's distributed behavior when you are running on the local network or in the same data center, but what about when you have 
multiple data centers, and what about when you have geo distributed data centers? Those are important considerations for the architecture of the system.
Because there are so many possible deployment options, I'm going to use AWS as the canonical example, simply because there is so much information about it
and you should be able to adapt the advice here to your need easily enough even if you aren't using AWS.

Inside the same availability zone (same data center) in Amazon, you can expect sub 1 ms ping times. Between two availability zones in the same region (separate
data centers^[Note, this assume that the connection between those data centers does not go over the public internet but dedicated lines. If the connection between
the data centers is over the public internet, expect higher latency and more variance in the timings.] that are very close by) you'll typically see ping times 
that are in the single digit millisecond range. 

The default configuration for the RavenDB cluster is each node expects to get a heartbeat from the cluster leader every 300 ms. When running in the same data
center, that is typically not a problem unless there is a failure of the leader (or the network), in which case the cluster as a whole will select a new leader.
However, what happens when we start talking about geo distributed data centers? Let's talk about the datacenters in Table 7.2. 


|  Data center  |      Tag       |
|---------------|----------------|
| N. Virginia   | us-east-1      |
| Ohio          | us-east-2      |
| N. California | us-west-1      |
| London        | eu-west-2      |
| Singapore     | ap-southeast-1 |

Table: A few AWS datacenters and their locations

Ping times^[The ping times between these data centers were taken from [https://www.cloudping.co/](https://www.cloudping.co/).] between those datacenters are quite
different. For example, N. Virginia to Ohio is 30 ms, N. Virginia to N. California is already at around 70 ms. From N. California to London is twice that at 140ms
and Singapore to N. Virginia clocks at 260 ms.

Given that the default configuration calls for an election if we didn't hear from the leader in 300 ms, it is clear that you can't just throw a cluster that is 
going to have a node each in N. Virginia, Singapore and London. The network latency alone would mean that we'll be unable to proceed in most cases. However,
that is just the default configuration and easily changed. The reason that I'm dedicating so much time to talking about latency here is that it has a lot of 
affect on your systems that you need to consider.

If we have the need to run in multiple data centers, or even in geo distributed data centers, we need to consider the latency between the datacenters and what it
means for your application. There are two options that we should consider, the first is having a datacenter spanning cluster and the second is to have a cluster
per datacenter.

#### Single cluster, multiple datacenters

When you have a single cluster spanning multiple datacenters you need to consider the expected latency and behavior. The actual configuration of the cluster
timeout is easy to set (the configuration option is `Cluster.ElectionTimeoutInMs`, defaulting to 300 ms), but that is the least interesting thing about this 
scenario.

When running in a geo distributed cluster, we need to consider what are the various operations that we use. The cluster timeout is merely the maximum amount of time
that the nodes will wait for a notification from the leader before deciding that there isn't a leader and that an election needs to be held. If there is work that
the cluster needs to do, it will not wait for the timeout to happen. Instead, it will always execute it as fast as it can.

On the other hand, an excessively high timeout value will mean that the cluster will take longer to detect that there is a failed leader and recover from that. In 
general, the cluster will typically recover from a failed node in up to to three times the timeout value so that needs to be taken into account. On the WAN, I'll 
suggest you raise the timeout to 3 - 5 seconds and see how stable that is for your environment. A lot of that depends on the quality of the communication between
the various nodes in your cluster. 

We talked a lot so far about the cluster and the effect of latency on the cluster, but most of the time we are going to operate directly with the database, not the 
cluster, so how does running in a geo distributed environment affect the database replication?

The answer is that it generally doesn't. The database level replication was designed for WAN, and doesn't have any hard timeouts like the cluster level. The cluster
needs to know that there is an active leader, because if there isn't, the node needs to step up and suggest itself as the next leader. But at the database level all
the nodes are equal, and any distruption in the communincation between the nodes is handled by merging the data from all the nodes at a later point in time, resolving
any conflicts that may have occured. This means that a database group is much easier to deploy in a geo distributed environment with high latency, because the 
nodes are fine with delays. 

> **Database instance distribution in the multi datacenter cluster**
>
> RavenDB assumes that all nodes in a cluster are roughly equal to one another, and when you create a new database it will assign instances of this database to nodes
> in the cluster, regardless of where they are located. If you are running in a multi datacenter cluster, you probably want to explicitly state which nodes this
> database will reside on, so you can ensure that they are properly divided between the different data centers.

Another consideration that you have to take into account is that there are also the clients. A client running on the London datacenter that connects to the Singapore
node for all queries is going to suffer. By default, RavenDB assumes that all nodes are equal, and the cluster will arbitrarily choose a node in the database 
topology that we'll typically work with. 

In the previous chapter, we talked about load balancing and how we can ask RavenDB to handle that for us automatically. One of the options available for us there is
`FastestNode`. This option will make each client determine which node (or nodes) are the fastest as far as it is concerned and access them according to speed. This
mode, in a geo distributed configuration, will result in each client talking to the node closest to it. 
That is usually the best deployment option for such an environment, because you are both geo distributed and able to access a local instance at LAN speeds. 

There is an issue that you need to handle, when your system is compose of parts far enough apart that can take hundreds of milliseconds just to send a packet back 
and forth there is the issue of consistency. If you are writing a document in one area it is not guaranteed that you'll see the write in another area. In fact, you'll
always have to wait until that write has been replicated.

We talked about write assruances and `WaitForReplicationAfterSaveChanges` in the previous chapter, but it is very relevant here. After you make write with the 
`FastestNode` option, the next session you open might access a different node. In order to ensure that the next request rom the user will be able to read the write
the user just made, you need to call `WaitForReplicationAfterSaveChanges`. Alternatively, if this is a write where a short delay in replicating to all the other 
nodes is acceptable you can skip it and avoid the need to get confirmation across the entire geo distributed cluster.

#### Multiple clusters, multiple datacenters

A single cluster spread over mulitple datacenters can be convenient for the operations team, since there is just this one cluster to manage everything with, but it
can also create headaches. For example, if we have 2 nodes in London and one node in N. Virginia, our leader will tend to always be based in London. Any outage 
between the two datacenters will leave the cluster fully functioning in London and unable to complete anything in N. Virginia (since it can't reach the other side).

Another problem is that failover _between_ datacenters is not something you'll want to do. You might want to fail _to_ another datacenter but failing a web app from
the N. Virginia datacenter all the way to the London datacenter impose a very high latency. If a page is making just 8 database requests, is it going to take over a
second to answer render a single page, and that is just calculating the network roundtrip costs. In such cases, it is often preferable to send the web traffic 
directly to the London datacenter until the N. Virginia datacenter is fully up again.

In such a scenario, having a single cluster will actually work against us. The problem is that the client API will automatically failover to any available node, but
in this case, we don't want that. We cannot tell the client not to failover to nodes in our cluster, that doesn't make sense. The appropriate way to handle this is 
to create separate clusters, one in each data center. In this manner, each datacenter's cluster is independent and manages just its own nodes. The client API in each
datacenter is configured to point to the nodes in that datacenter only. 

In this case, because failover stops at the cluster boundary, so there will be no failover between datacenters. But we still need to deal with a tough problem, how are we going to handle sharing the data between the separate clusters? 

#### Sharing data between clusters

A RavenDB cluster is a standalone unit, it manages itself and doesn't concern itself much with the outside world. There are situations, however, where you want to
have data shared between multiple clusters. This can happen if you want an offsite replica of all your data or if you have decided to have different clusters in 
each data center rather than a single cross data center cluster.

> **Replica isn't a backup**
>
> It is tempting to think that an offsite replica is also going to serve as the backup and not pay careful attention to the backup / restore portion of your
> database strategy. That would be a mistake. RavenDB's External Replication suppoert means that you get an offsite replica, but it doesn't provide good
> answers to a lot of backup scenarios. For example, protecting you from a "delete this collection" or "what was the state of the system in 9:03 AM last Friday?"
>
> An offsite replica gives you an offsite live copy of the data, which is very useful if you need to shift operations to a secondary data center, but it isn't
> going to allow you to skimp on backups. We cover backups (and restoring databases) in [Disaster Recovery and Plan B (for Backups)](#disaster-recovery).

Setting up replication between clusters can be done quite easily, because RavenDB make a strong distinction between cluster and database group interactions. 
In this case, this allows us to definea replication target that is not part of the cluster itself. We can do that in the database by going to `Settings` and 
then `Manage Ongoing Tasks` and adding an `External Replication` task. You'll need to provide the url and database name for the destination, and then save the
new replication. 
If you don't have an additional cluster to test this on, you can specify one of your own nodes and create a _separate_ database to replicate to.

> **Replicating to the same cluster**
>
> On the face of it, it seems very strange that we can setup an external replication from the cluster back to itself. Why make it an external replication, then?
> This can be useful if you want a copy of the data that wouldn't be a failover target for the clients. It may be an offsite backup or just a dedicated database
> that is setup so it will do some work (such as run ETL process). 

Ongoing tasks in general is quite interesting, and we'll discuss that at length in the next section. For now, we'll focus on what the External Replication feature
and what it means for us. Once we have finished configuring it, the cluster will assign one of the database group nodes to keep that replica up to date at all 
times.

It is important to remember that at the database level we treat it as just another destination, the cluster is _not_ managing it. That means that cluster 
level behaviors, such as defining conflict resolvers, failover for the client or index replication are _not_ send over. An External Replica is just that, 
external. You can configure both the source cluster and the destiation replica in the same manner, of course, but there is nothing that forces you to do so. In fact, 
the other common reason why you will want to setup an External Replica is to have _different_ configuration.

A good example of this is when you want to have expensive indexes and only run them on a particular machine. Maybe you need to run expensive analytics or to do
certain work on a specific location. Using External Replication gives you the ability to control the flow of the data without also dictating how it is going to
be processed. 

What would it take to have an offsite replica for our cluster? We'll use 


I mentioned earlier that once the External Replication is setup, the cluster will assign it to one of the nodes. We haven't discussed it yet, but that is one of
the more important roles of the cluster, deciding what work goes where. 

### Ongoing tasks and work distribution

The cluster as we know it so far isn't really smart. It give us the ability to distribute configuration, such as what databases goes where, what indexes are 
defined, etc. But it doesn't _do_ much. This is actually quite far from the way things are. This is because we have focused specifically on the flow of data 
inside a database group, rather then the flow of _work_. 

What does it mean, to have work assigned to a database group? The simplest example is the one we just talked about, external replication. If we have three nodes 
in this database group, which node is going to update the External Replica? We don't want to have all three nodes do that, there is no real point in doing so, 
and it can cause unnecessary network traffic. Instead, the cluster will assign this work to one of the database instances, which will be responsible for keeping
the External Replica up to date. 

Another example is hourly incremental backup of our data as well as a full backup on a weekly basis. We don't want to have this backup run on all three nodes at 
the same time, leaving aside the fact that this will increase the load on the system across the board, we don't really have anything to do with triplicate 
backups of the same data. This is where the work assignment portion of the cluster come into play. 

Whenever there is a task for a database group to do, the cluster will decide which node will actually be responsible for it. That seems pretty easy, but there is
actually a bit more to the story. Just assigning work is easy, but the cluster is also watching the nodes and checking how healthy they are. If a node is down, 
then the cluster will reassign the work to another node for the duration. 

In the case of a backup, if the node that is responsible for the backup is down when the backup is scheduled, another will shoulder the load and make sure that 
you don't have any gaps in your backups. In the case of External Replication another node will transparently take over keeping the External Replica up to date 
with all the changes that happened in the database group. 

Another type of work in the cluster that we already talked about in this book is subscriptions. The cluster will divide all the subscriptions between the various
nodes in the database group and reassign them on failure without your code needing to change anything (or even typically even be aware of that). Other types of
work that we can define for the database group include ETL processes, which are covered in the next chapter. 

### The supervisor's promotion

The cluster is continously measuring the health of each node in the cluster, using a component known as the supervisor^[I always imagine it in bright neon green
tights and a cape, flying around spouting cliches as it keeps everything in order.]. The supervisor will detect any errors in the cluster, react to a failed node
by reasssigning work and in general keep everything running.

This is important enough to mention here and not in the Operations portion of the book because the Supervisor also gives you a wealth of information about the 
state of the different nodes and database instances that are running on them. In particular, one of its most important roles is the promotion and demotion of 
database instances.

Given that RavenDB is a distributed database and not a military organization, what does it means, promotions and demontions? Consider the case of a database 
group that has two database instances. We want to increase the number of replicas so we add a new node to the database group. The process is pretty easy, all we 
need to do is to click on `Manage group` in the Studio and add the new node. 

On large databases, the process of adding a new replica can take a while. During that process, the newly added node isn't really part of the group. It cannot 
take over work in the group (we certainly don't want its backup until it is completely caught up, for example) and we don't want to failover clients to it 
(since it doesn't have the full data yet). Because of this, when you add a new node to a database group, it isn't added as a full fledged member, instead, it is
added as a promotable instance. 

What does it means, promotable? It means that it cannot be assigned work for the database group, that it cannot be failed over to. In fact, it _is_ work for the
database group, since one of the full members is going to have to start pushing data into this new node until it is fully up to date. This goes on until the 
supervisor can confirm that the new node is caught up with the state of the database group and that it finished indexing all the data that we sent to it. At 
this point, the supervisor will promote the node into a full member in the database group, work will be assigned to it and clients will consider as a 
failover target.

Conversely, when the supervisor detects that a node is down, it will demote it from a full member status into a promotable. This is done so when the node is 
coming back up, it will not start sending out outdated information. Instead, one of the other members in the database group will connect to it and update the 
recovered node until it is fully up to date, at which point the supervisor will promote it to full member again.

Using demotions and promotions as needed, the supervisor is able to communicate to clients (and the rest of the cluster) which are the authoritative nodes for a 
particular database group. Note that a failure doesn't have to be just a down node, something as simple as running out of disk space can also cause a database
on a node to fail and demote a node from being a full member. 

You won't generally need to handle such demotions and promotions yourself, or even really be aware of them. RavenDB is taking great pains to make the experience
of using the cluster as seamsless as possible, but you do need to understand _how_ this is happening so you can take advantage of RavenDB's behavior.


### Summary


We looked at some architectual considerations for building a RavenDB cluster and how to scale it to a large number of nodes and how we can share data 
between different clusters. Finally, we peeked into the management of the cluster itself, with the supervisor assigning work to the various nodes and constantly
monitoring their health, promoting and demoting nodes as needed.

This was anything but a trivial chapter, it is packed with new ideas and it tries to cover the whole of running a distributed cluster in a single chapter. I 
tried to make sure that the topic in this chapter follow logically one another as we tour through the distributed portion of RavenDB, but there is quite a lot
to go through. In particular, I haven't talked about operations, monitoring, statistics etc at all. I'm leaving all of that a chapter dedicated just for that,
[Statistics, Monitoring and Insight](#monitoring). We'll also talk a abit more about the implementation details that I intentionally skipped here, because the
operations team need to understand what is going on exactly, while this chapter was about the overall concept.




* External replication
* ETL
* Watchers
* Cross data center clusters
* Geo distribution with ravendb
* Clustering topologies ?? 


## Monitoring, troubleshooting and disaster recovery

We talked about deploying to production in the previous chapter, but just _being_ in production is only half the job. 
The other half is ensuring that your systems are up, running and answering queries faster than your SLA thresholds. 
In this chapter, we are going to cover how you are going to tell that your RavenDB cluster is healthy, monitor its 
state over time and what actions you should take if there are any issues popping up.

Even before getting the production deployment ready, you need to plan on how you'll monitor what is going on with 
RavenDB. The first thing you'll see when you go to the RavenDB Studio in the browser is the dashboard view, giving
you the most important details about what is going on with this RavenDB instance. This surfaces crucial details such
as the number of requests, CPU load, memory utilization, indexing rate, etc. 

The dashboard view was designed so you can just throw it on a monitor and take a peek every now and then to measure
the health of your system. If you have nothing else, just looking at the dashboard should still be enough to give you
some idea about what is happening on a particular node.

The problem with relying on only the RavenDB dashboard is that it shows you what is going on right now, and only on a 
single node. This isn't so useful if you want to have aggregated statistics across your cluster, including historical
information and analysis of behavioral patterns over time. For that, you need to use a dedicated monitoring system. 
RavenDB does not attempt to build a full blown monitoring solution in the dashboard, only to provide you with the most
pertinent information. The expectation is that you'll plug RavenDB into your existing monitoring solutions. Let's 
explore what kind of hooks are provided to plug into a monitoring solution by RavenDB.

### Ongoing monitoring

The most obvious monitoring option is to use SNMP^[Simple Network Management Protocol], which is available in 
RavenDB for Enterprise licenses. To configure SNMP in RavenDB you will need to setup SNMP as shown in Listing 16.1.

```{caption="Setting up SNMP using the settings.json configuration file" .json}
{
    "Monitoring.Snmp.Enabled": true,
    "Monitoring.Snmp.Port": 161,
    "Monitoring.Snmp.Community": "password"
}
```

Once you have the configuration options in Listing 16.1 in the `settings.json` file, restart the node and you can 
start querying RavenDB's internal state using SNMP. 
For example, the command in Listing 16.2 fetchs the server update from the public RavenDB test instance. 

```{caption="Getting the live instance server update via SNMP" .bash}
$ snmpget -v 2c -c ravendb live-test.ravendb.net 1.3.6.1.4.1.45751.1.1.1.3

iso.3.6.1.4.1.45751.1.1.1.3 = Timeticks: (84790246) 9 days, 19:31:42.46
```

The key parts of the commands are:

* `-v 2c` specify the protocol version to use (RavenDB uses RFCs 1901-1908)
* `-c ravendb` the community string (in the case of the public instance, it uses the default `ravendb`). If you use the 
  configuration in Listing 16.1, it will be `-c password`, etc. 
* `live-test.ravendb.net` the hostname to use, in this case, we use the live instance, but you will plug your own 
  instance URL there, of course.
* `1.3.6.1.4.1.45751.1.1.1.3` the OID that we are querying, in this case, we are asking for the server uptime.

The output is the server uptime, and we told RavenDB that we wanted this value using the OID. 
OID stands for Object Identifider, which is a way to globally name a particular value. The 
[`1.3.6.1.4.1.45751`](http://oidref.com/1.3.6.1.4.1.45751) prefix belongs to RavenDB and anything nested under that
is used to denote particular values that can be queried. Instead of making you memorize all of those OIDs, you can 
ask RavenDB to give you a list of all the OIDs that are supported by a particular instance. 

Querying the available OIDs is done by calling to the `/monitoring/snmp/oids` endpoint on your server. For the live
test server, that would be 
[http://live-test.ravendb.net/monitoring/snmp/oids](http://live-test.ravendb.net/monitoring/snmp/oids).

The later can be very helpful because it also gives you the OID for specific values in specific databases. For 
example, the `1.3.6.1.4.1.45751.1.1.5.2.2.2.1` OID can be used to tell us how big in MB is a particular database.
This can make it very easy to plot all sort of interesting values over time. You can also use this to monitor 
the index rate of a specific index in a particular database. The amount of details and control you have is extensive.

Of course, you aren't usually going to be querying SNMP OIDs using `snmpget`, you are going to be plugging this 
directly into a monitoring solution such as Zabbix, Nagois, SCOM, OpenView, etc. The online documentation has a few
walkthroughs to help you setup some common scenarios, but I'm going to assume that you are familiar with your own
monitoring systems and will skip any further handholding at this point.

> **RavenDB isn't the only source of monitoring data**
>
> RavenDB exposes a lot of information about its internal state to make it easier to figure out what is going on.
> At the same time, we don't try to expose _machine_ state via SNMP. RavenDB assumes that you can get that directly
> from the machine using standard monitoring metrics (`1.3.6.1.2.1.25.3.3` OID to get per core CPU load, for example).
>
> When setting up monitoring, be sure to include metrics for anything that is useful. CPU, memory, network and I/O 
> are among the most common values that should be tracked. In most systems, these are part of the standard templates
> and require very little effort to setup. I mention this explicitly because tracking just the values that RavenDB
> can provide will paint only part of the picture. 

Beyond using SNMP, RavenDB also expose a lot of state in REST endpoints outputting JSON that you can use. 
These are meant to both for humans to look at during troubleshooting and for automated systems to scrape and store
the data over time. Most monitoring solutions have a way for you to provide a URL and a path in the response to gather
interesting values to keep. 

You can get the full list of the debug endpoints from your server's `/debug/routes` endpoint. For the live test server
this would be [http://live-test.ravendb.net/debug/routes](http://live-test.ravendb.net/debug/routes). Just like any
other endpoint in RavenDB, when running in a secured mode, you'll need to authenticate using a client certificate. 
Each monitoring solution have a different way of specifying that, so you'll need to check the user's manual for
exactly how that work.

#### What should be monitored?

Now that we know how to get the values to monitor, the obvious question is what _should_ be monitored? 
I'm afraid that this is a hard question and a lot depends on your actual usage and needs. CPU, memory, network and 
disk I/O are the most obvious things that you want to pay attention to.
The number of requests and number of writes are also very interesting in almost all cases. 

> **Why not just monitor _everything_?**
>
> You can most certainly capture and store all the values that RavenDB and the machines expose. The problem with 
> looking at all of them is that there are a lot of information there that has no value for most scenarios, so 
> you might end up with a needle in a haystack situation. It's easy to fail to see the pertinent information because
> you are drowning is so many other details.

You most certainly want to monitor values such as the number of alerts for each of your databases, but seeing the 
time since last query for each index is probably not that interesting. 

The general recommendation is that you'll start with the basic template (see the online documentation for more 
details on that) and add more details as you see the need for that. A lot of that depends on whatever you are 
seeing some signs of trouble and you want to head them off early on.

This is vague, I'm aware, but the problem is that it is very hard to give good advice in a generic manner. One
scenario may call for B2B system with fairly constant load, so seeing CPU percentage go too low or too high is 
a good indication that something is not right. Another scenario would be a user facing system where during 
lunch time there is hardly any activity, but there is a very clean 9AM spike very single working day. 

There is no substitution for knowing your environment and what is expected. Once you know that you can set
set thresholds for alerting the operations team when the monitored values are not in the expected range. Some
monitoring tools can even analyze the data on their own and detect when there are irregularities in the data
and point that out for you. 

#### Performance hints and alerts

RavenDB itself is constantly monitoring its own health. This includes measuring I/O latencies, conenctivity
to other nodes in the cluster, amount of memory and disk that are available, etc. For some of these values, RavenDB
will take direct action. For example, if the memory is low, RavenDB will switch gears and try to reduce the 
amount of memory it is using to avoid running completely out of memory. 

Most of the time, however, there isn't much that RavenDB _can_ do. For example, if there is no free space on the 
backup folder or if RavenDB is experiencing slow I/O. What RavenDB can do is let you know about these 
troublesome details. RavenDB expose such issue as performance hints and alerts, shown in Figure 16.1.

![Alerts and performance hints give your operations team hints about what to look at](./Ch16/img01.png)

Alerts are issues that RavenDB encounters that require some sort of manual intervention. It may be something simple
such as running out of disk space or network issues talking to a particular database. Sometimes the errors are 
transient, which is common in network scenarios. They'll generate an alert for your perusal, even if the actual 
error was fixed (connection resumed between the nodes) because it can be important to investigate what happened
after the fact.

> **Alerts are node-local**
>
> An alert isn't a cluster wide notification. Indeed, in many cases, you'll be alerted that a node is unable to 
> talk to the rest of the cluster. As such, you need to monitoring each node in the cluster and check its state
> whenever there an alert. 

Performance hints, on the hand (the blue box Figure 16.1) are different. These aren't things that denote errors, 
but they very likely do demand attention. RavenDB generate them for various reasons, such as the slow I/O sample
in Figure 16.1. Other reasons include queries that return very high number of results without using streaming, 
slow requests, high fanout in indexing and a few other common issues.

These aren't typically of high severity, but it is better to fix them early. These kind of hints are generated 
whenever RavenDB detects a usage pattern that is known to be problematic. For example, if your queries have a
very large page size, or your documents are very big, these are commonly cause for issues. RavenDB will be 
proactive in bringing these to your attention. 

In general, alerts are designed as an acknowledgement that no one reads the logs until it is too late. Instead
of hiding errors in a text file that no one reads, RavenDB ensures that your operations teams know about the 
stuff that they need to.

#### The debug log

Alerts are high level items that needs operator attention, by design, there are very few of these and RavenDB will
avoid spamming your operations team with too many cries for attention. In addition to the alerts and hints system, 
there is also the debug log.

RavenDB has just two log levels: `Operations` and `Information`. By default, RavenDB will log only messages 
with the `Operations` label. Operational log messages are things that the operations team need to pay attention to
or be aware of. That include actions such as updating certificates, failure to process commands, background tasks
errors, etc. 

At this level, the logs output is meant to be readable and fairly shallow. You aren't informed about anything that
goes on inside RavenDB. You only hear about the kind of stuff that should matter to the operations teams. That is
mostly errors and issues, even if they were transient or worked around by RavenDB.

> **The audit log**
>
> In addition to the `Operations` level, RavenDB also support an explict audit mode, in which RavenDB will record
> all connections to the database, the source of the connection, the certificate used and what access level was
> granted to the connection.
>
> Certain special actions, such as creating databases or indexes are also written to the aduit log. To enable the
> audit log, you can set `Security.AuditLog.FolderPath`. We covered the audit log in more details in Chapter 13. 

The `Information` level, on the other hand, is much more detailed and will include a detailed log of anything that
goes in the database. That can be helpful when tracking down a specific issue, but generally that results in a _lot_
of data that goes to the log. On a busy server, you can easily see a log file rollover (which happens every 256MB)
in 5 - 10 minutes.

By default, RavenDB retain log files for 72 hours. After that, it will delete the old log files. In many cases, 
you'll have a logs agent monitor the directory and send the logs to a central location, which means that you can 
delete the logs file as soon as RavenDB starts a new one.

The logs location is controlled by `Logs.Path` configuration option and it generally recommended to have RavenDB
write the logs to a separate hard disk. This is primarily to avoid the case of setting the `Logs.Mode` to the 
`Information` level and have the logs fill up the RavenDB data disk completely. 

Changing the logs path or the logs mode requires a server restart. But that isn't the only way you can use to get
information from RavenDB.

### Finding out your server is doing

If you run into issues with RavenDB, it might be too late to setup logging and monitoring. Recognizing this reality
RavenDB has a lot of knobs to tweak and places to peek into the internals of the engine. This does _not_ mean that you
can skip setting up proper monitoring regime. The techniques outlined in the section are very useful when trying to 
understand the behavior of RavenDB.

In many cases, they can help you pinpoint what is going on very quickly. Monitoring, on the other hand, gives you 
insight into the behavior of the system over time and alert you if something is out of whack. It is expected that
any production cluster will have a proper monitoring strategy.

The RavenDB Studio provide explicit support to figure out what is currently going on. The first place to look at is
inside `Manage Server` and the `Debug` section, shown in Figure 16.2.

![The `Debug` section is your first stop to figure out what is going on the inside](./Ch16/img02.png)

These options are typically only available to the operations team (requiring `Operator` or `Cluster Admin` privileges).
This is because they contain data for the entire server, not for a particular database. A standard user will not be
able to use these features. 

Let's explore each one of these options in turn.

#### The admin logs view

The easiest way to figure out what is going on inside RavenDB is to use the `Admin Logs` feature. This allow you to 
hook into the logs stream that is generated by RavenDB and view that on the browser. It is a very convient option 
because it doesn't require you to do anything to the server.

Even if the server is configured to not log anything, going to the `Admin Logs` page will start streaming the log
entries to you at `Information` level. This means that you can enable the logs and watch them only during interesting
periods, instead of having them on all the time (or having to restart the server to change the logs mode).

Errors will be highlighted in red, but do note that there are many errors that are actually expected and handled by
RavenDB, so seeing some errors isn't something that you should be frightened of. 

#### The traffic watch view

Looking at the logs can be fairly tedious, given how much information is being generated. In some cases, it is easier
to figure out what is going on by just looking at the requests that are being made. RavenDB contains a dedicated
view for that, as you can see in Figure 16.3. 

![Watching live requests on a production database can be helpful in many cases](./Ch16/img03.png)

In Figure 16.3 you can see each individual request, how much time it took as well as some statistics about all the 
requests that were captured during a specific session (number, min, avg, max duration). That can be very helpful if 
you want to figure out why something is slow or result in an error. You can also export the traffic capture for 
later analysis. 

#### The debug info package

By far the most valuable tool to inspect the state of RavenDB is the `Gather Debug Info` page. You can see how this
looks like in Figure 16.4. 

![The `Debug Info` pacakge gives us access to _all_ the RavenDB debug endpoints](./Ch16/img04.png)

What this page does is to give us the ability to generate, at the click of a single button, a snapshot of the current
state of the RavenDB instance or even the whole cluster. The result is a single `zip` file that you can send along 
with your support ticket or do offline analysis at a later date.

I mentioned a few times before that RavenDB goes to great lengths to externalize its state. Even with this chapter, 
dedicated to talking about how you can figure out what RavenDB is doing, I'll not have enough time and space to go
over all the details that are available. Some of them are extremely useful, for a single specific case. Most of the 
time, you don't really need to go over each and every one of them.

The ability to capture all the state at once, easily and with no fuss, means that if you are in a bad state, you can
get the current status of the system and then take potentially invasive operations to fix this. The classic example
is rebooting the system, which will "fix" many issues. The problem is that if you do so, you'll also typically lose
crucial information about what went wrong and how to prevent it in the future. 

The `Debug Info` package allows you to retain all of that knowledge. It also is very useful if you need to contact
the RavenDB support team, since it saves a _lot_ of back and forth. 

#### Advanced details

The last item in Figure 16.2 is the `Advanced` options, where RavenDB puts details that can be very interesting, but
aren't usually needed. Among them, we have two very interesting views.
You can see these in Figure 16.5.

![Advanced information about what is going on inside RavenDB](./Ch16/img05.png)

Figure 16.5 shows the threads details inside RavenDB. This can tell you what exactly is costly in terms of CPU time. 
The list is sorted by usage order, so threads that burns through a lot of CPU will show up first. In this case, you 
can see that the most expensive thread is the `Voron Global Flushing Thread` (we'll discuss I/O, which is what this
thread is doing, later in this chapter) and then an indexing thread. 

RavenDB typically names threads to make it easier for you to figure out what is it that they are doing. This allows
the operations team to figure out what is costing you and take actions accordingly. 

Another interesting peek into the internals of RavenDB is offered by the `Cluster Observer Logs` view. 
In Chapter 7 we discussed how RavenDB Cluster will assign work and even move databases between nodes automatically.
Figure 16.6 shows the logs of such decisions, allowing you to examine and understand them.

![The cluster observer logs explains how the cluster makes decisions](./Ch16/img06.png)

The logs in Figure 16.6 shows that Node B was down, and at what point the cluster detected that this node's databases
caught up with the rest of the nodes in the database group, allowing the cluster to move node B from a rehab state
to a normal member state.

> **Operational stability**
>
> One of the worst things a piece of software can do to an operations team is to surprise and mystify them. 
> Surprises are almost never a good idea in production. And a good mystery is wonderful when it comes in book
> form, but not if it means figuring out what blew out production. 
> 
> The cluster observer routinely  monitor the health of the entire cluster, making
> decisions about where traffic should go and what nodes are reliable. 
> By default, it is only going to take action if a node is down for a long time (15 minutes or more). 
>
> This means that it isn't going to start taking action before you can react. You can also ask the cluster 
> observer to suspend any actions for a while, if you know that you are going to take some maintenance operation
> that will make the observer take action usually. This is done using the `Suspend cluster observer` button shown
> on Figure 16.6. 

This can be very useful if you want to understand how the system got into its current state, and what has led the
cluster observer to make the decisions it did. This is also logged, of course, but it is usually much easier to 
see the information condensed in such a manner than search through the log files. 

### I/O operations in RavenDB





### The admin JavaScript console


I/O behavior of RavenDB
	- Voron
	- Writes
	- Reads
	- Expected metrics


Disaster recovery
	- Voron.DisasterRecovery
	- How to bring a cluster up from a single node
	- rvn and the ravendb cli
	- recovering the keys to a cluster
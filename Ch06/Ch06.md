
# Inside RavenDB Indexes

In this chapter, we are going to go over a lot of the theoretical details and reasoning behind how RavenDB indexes work. You'll not actually learn how to _use_ the indexes in this query, but you'll learn all about their details. You can feel free to skip this chapter for now, and go straight ahead to the next one to read the practical details on using indexes. But come back here and read this chapter at your leisure, it contains a lot of very important information about how RavenDB operates internally.

We have already done quite a bit with RavenDB, but we haven't talked about indexing at all and very little about querying. That doesn't mean that we didn't _use_ indexes, however. Let us consider the following query:
	
	var recentOrdersQuery =
		from order in session.Query<Order>()
		where order.Company == "companies/1"
		orderby order.OrderedAt descending
		select order;

	var recentOrders = recentOrdersQuery.Take(3).ToList();

How does a query like that work, on the server side? If you are used to relational databases, you might assume that the following pseudo code is run:

	var results = new List<Order>();
	foreach(var order in GetAllDocumentsFor("Orders")) {
		if(order.Company == "companies/1")
			results.Add(order);
	}
	results.Sort((x,y) => y.OrderedAt.CompareTo(x.OrderedAt));

This type of operation is called a table scan, and it is quite frequent in relational databases. This is also quite efficent, as long as the number of items you have in the database is very small. It tends to fail pretty horribly the moment your data size reach any significant size.
I've run into variants of this issues at customers over and over again, and when the time came to designing RavenDB, I decided that as part of the Safe By Default culture, we will simply not support this problem.

*RavenDB does no table scans!* In fact, there are no O(N) operations in general in RavenDB queries. Given the title of this chapter, I'm sure that you can guess how we handle queries. We use indexes to speed up queries. Using an index turn a query from an O(N) operation to an O(logN) operation. For those of you who don't care about abstract computer science stuff, the difference is between waiting 30 minutes for a result, or getting it right away.

> **We haven't created any indexes, but we can query!**
>
> Yes, that is confusing, isn't it? RavenDB doesn't allow queries without an index to answer the question. Yet at the same time, it does support queries without first defining an index. 
> 
> The answer is very simple, RavenDB is a pretty smart beast, whenever you make a query, the query optimizer get a chance to look at that, and it select the appropriate index to use. But what happens when we don't _have_ such an index? Well, you obviously want to query that information, otherwise you won't have send the database this query. What to do...
> 
> The query optimizer at this point can figure out what you need to be index, and it will _create this index for you_. The details of this process are explained later in the chapter, but the key part to understand is that RavenDB can automatically optimize itself to answer the kind of queries that you execute.
> This happens on the fly and without requiring any human involvement. The more you use RavenDB, the smart it become and the faster it is in responding to requests.

But we are jumping ahead of ourselves here, we'll discuss the ad how querying optimization RavenDB does in the [dynamic indexing](#dynamic-indexing) section. Before we get there, let us look at a few standard RavenDB indexes first.

## How indexing works in RavenDB?

An index is a way for the database to organize information about your data so it will able to retrieve said data efficiently. Let us look at an index definition in RavenDB. In this case, we want to index the `Name` property of a `Product`, so we can search for a product by name. Listing 6.1 shows a simple index that will allow us to answer such a query.

```{caption="{Index definition for searching products by name}" .cs}
from product in docs.Products
select new 
{ 
	product.Name 
}
```

This doesn't look very much like an index, does it? It looks a Linq query. In fact, if we were to excute this query we'll get the following results:

----							----						
Alice Mutton					Chocolade					
Aniseed Syrup					CÃ´te de Blaye				
Boston Crab Meat				Escargots de Bourgogne		
Camembert Pierrot				Filo Mix					
Carnarvon Tigers				Flotemysost					
Chai							Geitost						
Chang							Genen Shouyu				
Chartreuse verte				Gnocchi di nonna Alice		
Chef Anton's Cajun Seasoning	Gorgonzola Telino			
Chef Anton's Gumbo Mix			Grandma's Boysenberry Spread
----							----						
Table: First 20 product names, sorted.

So how can this be an index? The answer is that this isn't actually the index. The link expression above is actually the _index definition_, this determine _what_ will be indexed (as well as exactly how, but we'll touch on that later). How does that work?

Let us look at Listing 6.1, this is the external respresentation of the index, but internally, we add need to track where the details came from so the end result is:

	from product in docs.Products
	select new { product.Name, **product.__document_id** }

The output of the index definition is a list of objects with a `Name` and a `__document_id` property. But what can we do with this? 

> The following isn't actually how this work in RavenDB, we'll get to the full details of that in a bit. This is an attempt to explain how RavenDB works by simplyfing things as much as possible.

Now that we have the data to be indexed, we can actually put this in the index. From a logical perspective, Listing 6.2 shows what is going on after we have the index

```{caption="{Logical view of storing index entries in the index}" .cs}
var index = new Dictionary<string, string>(); // name --> doc id
foreach(var indexEntry in results)
	index[indexEntry.Name] = indexEntry.__document_id;
```

And queries now become a simple issue of reading through the index and then sending the results back, as shown in Listing 6.3.

```{caption="{Logical view of querying the index}" .cs}
// query for Name = Chang

var docId = index["Chang"]
return LoadDocument(docId);
```

Again, this isn't actually how it works, but it is a simple way of thinking about this.	And right now I want you to understand the general concept, rather than the actual details.

> **The `__document_id` property**
>
> The __document_id` is a reserved property named in RavenDB, it maps to the document id of the document, regardless of the client side convention. 

So, we use a linq expression to select the fields to index from our documents. We also add the relevant document id to the output, and then we put all of those details in an index. When we query, we use the index to figure out what is the actual document id that match the query, and then we load the document (or documents) from storage by id, and send it to the client.

For the rest of this chapter (and in general), we'll use the following terminology:

* **Indexing function** - the linq expression (such as the one in Listing 6.1) used to project the fields to be indexed from the documents.
* **Index entry** - the output of the indexing function. A single document can output zero or more index entries.
* **Indexing run** - the execution of all the indexes on a batch of documents. 

## Incremental indexing

By now, you have almost all the pieces you need to understand how RavenDB indexing works. In Chapter 4, we discussed [etags](#etags). An etag is just an ever increasing number that changes whenever a document changes. Because a RavenDB database can contain a _lot_ of documents, it isn't practical to run the indexing function over the entire data set every time. Instead, we do incremental indexing, and we do that using the etag. Listing 6.4 shows a simplified version of how indexing works.

```{caption="{Highly simplified indexing process}" .cs}
while (databaseIsRunning) {
	var lastDocEtag = GetLatestEtagForAllDocuments();
	var lastIndexEtag = GetLastIndexedEtagFor("Products/ByName");

	if(lastDocEtag == lastIndexEtag) { 
		// index is up to date
		WaitForDocumentsToChange();
		continue;
	}
	
	var docsToIndex = LoadDocumentsAfter(lastIndexEtag);
	for(var indexEntry in indexingFunc(docsToIndex)) {
		StoreInIndex(indexEntry);
	}
	SetLastIndexEtag("Products/ByName", docsToIndex.Last().Etag);
}
```

I'll repeat again that Listing 6.4 shows the _conceptual_ model, the actual working of this is very different.

## The indexing process

In relational databases, indexes are computed as part of the same write transaction. That leads to an interesting tradeoff. If you don't have the right indexes, you are falling back to a table scan, and all the performance degredation that comes with that. So you want your indexes to cover all the columns you are querying. But the more indexes you have, the slower writes become.

It ends up being up to the DBA, who need to make a judgement call. And often the DBA need to make that judgement call without a lot of information. The decision need to be made upfront, before the DBA has any actual performance numbers (because the application hasn't been created yet). With RavenDB, we chose a different approach.

Instead of executing the indexes as part of the write transactions, we run them as a background task. You can see a hint of that in Listing 6.4. This code (or rather, its conceptual cousin) is always running in the background, and whenever there is a change in the documents, the indexing function is run on the new or updated documents.

This has some interesting implications. The most obvious one is that there is an inherit race condition between updating a document and the indexes catching up with that update. Usually, the time between a document being updated and the relevant indexes being updated is measured in milliseconds, usually between 15 - 25 ms. 

> **Staleness in the real world**
> 
> At first sight, the idea of a query that may not be fully up to date sounds scary. But in practice, this is how we almost always work in the real world. The trivial counter example that I keep getting thrown in my face is financial transactions.
> 
> "Of course that you need full consistency for everything financial", they tell me. Try this, call you bank and ask them how much money you have in your account. The answer you'll get is going to be some variant of: "As of last business day, you had...".
> 
> Or let us take a pure software example, if you create a new bug, does it matter if your manager sees it right away, or wait an additional 25 ms to get it? This design choice was made explicitly, and it has quite a lot of benefits to it (detailed below).
>
> One very important factor to note is that RavenDB will always _tell_ you if you are getting potentially stale results, but more on that later.

The other implications of this design decision is that you the kind of promise the RavenDB database engine is drastically different than the kind of promises a relational database engine will give. A relational database will promise you that you'll have a fully consistent view of the universe. The problem with that is that it is very costly to actually do this. That is why relational databases has the concept of transaction isolation levels, and why very few of them opt to default to a high isolation level.

It is just too costly to do so. In order to keep its promise, the relational engine has to take locks, and do a lot of extra work to isolate different transactions from each other. The more transactions you have, the higher the cost. Until at a certain point, the relational database is overload and it will throw its hands up in the air and go sit in the corner while it is having a funk.

Your application, in the meantime, will start erroring (if you are lucky) or just hang, waiting for the relational database to respond.

With RavenDB, you get a different kind of promise. RavenDB will promise to:

* Give your immediate results based on what we currently have in the index.
* If the current state of the index isn't up to date, RavenDB will tell you so, including how up to date the index is.
* RavenDB will make its best to reduce the indexing latency.
* You have the option to explicitly wait for the results to become non stale.

> **Documents are always consistent**
>
> RavenDB uses the terms stale and non stale to refer to out of date indexes. This is done intentionally, because consistency is always maintained. 
> 
> Listing 6.3 showed how queries work, from a logical perspective. We first consult the index to find a match for the query we are executing. Once we have the match, we have the relevant document id. Using that document id, we go to the document storage and load that document by id.
>
> The RavenDB's document storage subsystem is fully consistent^[For the database nerds, which I assume that you are if you are reading this book, the document storage subsystem implements Snapshot Isolation and optimistic write locks.], so you are always getting the latest committed version of the document.

Why is it important that RavenDB has a different set of promises than a relational database? 

Because by making a different set of promises, we have opened ourselves to a great deal of optimization opprtunities. Here are just a few of those that are implemented in RavenDB.

### Throughput vs. Latency

I/O rates is usually the most expensive part of indexing. And it doesn't really matter if we are indexing a single document or a hundred, the base I/O cost of an indexing run is high enough to overshadow all other costs. Because of that, RavenDB utilizies several stratgies when it comes to indexing. 

Under light load, RavenDB uses a low latency / low throughput strategy. Documents will be indexed as soon as possible, and while the I/O cost of that can be high, it doesn't matter, because we would don't have enough load to saturate the system. But when the load gets higher, RavenDB automatically switches to a different strategy. The high latency / high throughput strategy. Under those conditions, we are going to run fewer indexing runs, but each indexing run will have more documents that need to be udpated. This allows us to amortize the I/O cost of indexing over a large set of documents, resulting in a greater efficency all around.

> **What is with all the implementation details?**
> 
> You don't really need to know all those details. And even though I'm going over the details, I'm still leaving a lot of stuff out. 
> We are constantly tweaking this part of RavenDB in attempt to achieve higher performance and better throughput, so the details are subject to change.
> 
> But it is good to have a proper understanding of at least the kind of challenges that we have to go through, and the overall strategy to handle them. It can help you understand why RavenDB behave in a certain way in specific situations.

During indexing, we have to balance a fair number of variables to try to get to an optimum result. Indexing uses a lot of memory, we need to have the source documents to index, the actual output from the indexing function, generating the index itself, etc. Indexing is also a compute intensive operation, especially if you are using spatial indexing or require suggestions support. Indexing use a lot of I/O, because it needs to read the source documents, and write the index entries to disk.

> **Indexing scenarios**
>
> There are two common scenarios that pop up when talking about indexing. The new index mode and the steady state mode. In the new index mode, we have a new index defined, which need to index the entire data set. With large data sets, that can take a while.
> 
> The steady set mode is the usual way RavenDB runs, when most of the data is already indexed, and we only have to work on indexing the new/updated documents as they are written to the database. There are different optimizations for each scenario, and the interesting thing happen when we are actually creating a new index at the same time as we have existing indexes and a steady rate of writes to the database.
>
> In other words, a typical production setting, especially since we can expect indexes to be introduce to the system on a fairly regular basis in production (by the query optimizer, for example). Unlike many relational databases, introducing a new index to a production system result in no locks, and it is perfectly fine to do so. There is a cost in the actual indexing, but RavenDB knows how to manage that to avoid using too much.
>
> The level of trust we have in this system is so high that we let an automated component make indexing decisions on the fly, to self optimize your database.

The indexing code in RavenDB need to balance competing requirements between all those resources, and at the same time, make sure that we aren't overwhelming the machine we are running on. The other side of that is that if we have a lot of resources on the machine (many cores, lot of memory, SSD drives), we want to make the best use of those resources that we can. Let me see if I can explain how we try to maximize resource utilization without using _too_ much.

### Parallel indexing 

Let us assume that you have a database with a million documents in it, and you just created ten new indexes. The server machine has 4 cores and 8 GB of memory. What would happen now? Each of the indexes need to go over the entire data set. One way to handle this is to spin up a thread for each index, point it at the documents, and let it run. This has a lot of issues. To start with, each of the indexes are going to need the same source data (the documents), so just running each independently will result in a lot of duplicated I/O and memory usage. It also turn out to be problematic because we might actually generate so much CPU work that we won't have the time to process requests, if we have ten threads doing compute intensive work.

The actual indexing process in RavenDB is split into runs. On each run, we load a batch of documents, then select a number of indexes^[the exact number depend on your configuration and license, but on the system we specified, it will be 4 - 8, usually.] and let them run on that batch. When those indexes are done, it will select the next set of indexes to run, and so on until we are done with all the indexes that are relevant for this batch.

> **Parallelism at the single index level**
>
> RavenDB also parallelise work at the single index level. A single index that need to process a large number of documents will also execute the indexing work in parallel. The idea is maximize parallelism at both the single index level and among all indexes.

If there are still documents to be indexed, we'll then fetch the next batch of indexes, and go through the process again. The reasoning behind limiting the number of concurrent index executions is that each index is going to be doing a lot of compute intensive work (indexing) as well as use up memory. By limiting the nubmer of indexes that execute concurrently we can reduce the overall indexing cost.

### Auto tuning batches

We mentioned batches a few times, but let us talk about what those batches actually _are_. At the simplest level, a batch is just a collection of documents, just "give me the next 128 documents after this etag by etag order". Because we feed batches into the indexing process, the actual size of the batch is quite important. The biggest the batch, the more work the indexes will do, and the longer they will take to run. But because there are fixed I/O costs per batch, the bigger the batch, the less time we take _per document_, up to a point.

A question come up then, how do we decide what the batch size would be? This seems to be a typical configuration value that we'll let the administrator decide. But that is a pretty sensitive option, with regards to the system performance, and we don't want to have the administrator on call to start modifying this config value in production if things change. That is why RavenDB doesn't have a configuration value for this property. Instead, it has a configuration _range_ (min and max values). The RavenDB engine will determine the optimal batch size within this range automatically.

When there isn't a lot of work to do, the batch sizes are going to be small, favoring low latency (and low throughput). But when we are facing a high write situation, or when we have to index a lot of data (such as when we have a new index on a large database), RavenDB will note that the small batch sizes aren't enough to process the data quickly and start increasing the batch size. This is controled by many factors (current indexing time and available memory, among many), to avoid creating a batch size that is _too_ large, but in practice, this works very well.

When we have a large number of items to index, we will slowly move to a larger batch size and process more items per batch. This is the high throuput (but high latency) indexing strategy that we talked about. When the load goes down, we'll decrease the batch size to its initial level. This seemingly simple change has dramatic implications on the way RavenDB can handle spikes in traffic. We'll automatically (and transparently) adjust to the new system conditions. That is much nicer than waking your administrators at 3 AM.

### I/O Considerations

I/O is by far the most costly part of the indexing effort, and the hardest to optimize. This is because RavenDB can run on systems that have persistent RAM disks (so reading from disk is effectively free) to virtual disks whose data is actually fetched over the network (so I/O latency is _very_ high). Note that this applies for both reads and writes. Indexing need to read (potentially a large amount) of documents so it can actually index them, and it need to write (much smaller) amount of data to the index.

In order to best utilize the system resources, we have a component called the prefetcher queue^[This is used by the indexing processes and by replication] that is responsible for supplying the indexes with the next batch. We do that using several ways. In the steady state mode, whenever a new document is added / updated, we also register it in the prefetchers. That means that normally, indexing does need to hit the disk at all, it can index completely from memory.

For indexes that need to access data that is already on disk, we apply a different optimization. Whenever the prefetcher is done handing out a batch, it start an async process to load the next batch to memory. That way, when the indexes are done and want the next batch, it is already ready for them and can hand the next batch immediately.

The actual behavior is pretty complex, because we don't want to load so much data so we won't have enough memory to do the actual indexing, and document sizes aren't fixed. We also need to take into accoutn the I/O speeds that we can get. 





## Working with stale results

## Lucene 

## Dynamic indexing

## How RavenDB index documents?

# Inside the RavenDB indexing implementation

In this chapter, we are going to go over a lot of the theoretical details and reasoning behind how RavenDB indexes work. You'll not actually learn how to _use_ the indexes in this query, but you'll learn all about their details. You can feel free to skip this chapter for now, and go straight ahead to the next one to read the practical details on using indexes. But come back here and read this chapter at your leisure, it contains a lot of very important information about how RavenDB operates internally.

We have already done quite a bit with RavenDB, but we haven't talked about indexing at all and very little about querying. That doesn't mean that we didn't _use_ indexes, however. Let us consider the following query:
	
	var recentOrdersQuery =
		from order in session.Query<Order>()
		where order.Company == "companies/1"
		orderby order.OrderedAt descending
		select order;

	var recentOrders = recentOrdersQuery.Take(3).ToList();

How does a query like that work, on the server side? If you are used to relational databases, you might assume that the following pseudo code is run:

	var results = new List<Order>();
	foreach(var order in GetAllDocumentsFor("Orders")) {
		if(order.Company == "companies/1")
			results.Add(order);
	}
	results.Sort((x,y) => y.OrderedAt.CompareTo(x.OrderedAt));

This type of operation is called a table scan, and it is quite frequent in relational databases. This is also quite efficient, as long as the number of items you have in the database is very small. It tends to fail pretty horribly the moment your data size reach any significant size.
I've run into variants of this issues at customers over and over again, and when the time came to designing RavenDB, I decided that as part of the Safe By Default culture, we will simply not support this problem.

*RavenDB does no table scans!* In fact, there are no O(N) operations in general in RavenDB queries. Given the title of this chapter, I'm sure that you can guess how we handle queries. We use indexes to speed up queries. Using an index turn a query from an O(N) operation to an O(logN) operation. For those of you who don't care about abstract computer science stuff, the difference is between waiting 30 minutes for a result and getting it right away.

> **We haven't created any indexes, but we can query!**
>
> Yes, that is confusing, isn't it? RavenDB doesn't allow queries without an index to answer the question. Yet at the same time, it does support queries without first defining an index. 
> 
> The answer is very simple, RavenDB is a pretty smart beast, whenever you make a query, the query optimizer get a chance to look at that, and it select the appropriate index to use. But what happens when we don't _have_ such an index? Well, you obviously want to query that information, otherwise you won't have send the database this query. What to do...
> 
> The query optimizer at this point can figure out what you need to be index, and it will _create this index for you_. The details of this process are explained later in the chapter, but the key part to understand is that RavenDB can automatically optimize itself to answer the kind of queries that you execute.
> This happens on the fly and without requiring any human involvement. The more you use RavenDB, the smart it become and the faster it is in responding to requests.

But we are jumping ahead of ourselves here, we'll discuss the ad how querying optimization RavenDB does in the [dynamic indexing](#dynamic-indexing) section. Before we get there, let us look at a few standard RavenDB indexes first.

## How indexing works in RavenDB?

An index is a way for the database to organize information about your data so it will able to retrieve said data efficiently. Let us look at an index definition in RavenDB. In this case, we want to index the `Name` property of a `Product`, so we can search for a product by name. Listing 6.1 shows a simple index that will allow us to answer such a query.

```{caption="{Index definition for searching products by name}" .cs}
from product in docs.Products
select new 
{ 
	product.Name 
}
```

This doesn't look very much like an index, does it? It looks a LINQ query. In fact, if we were to execute this query we'll get the following results:

----							----						
Alice Mutton					Chocolade					
Aniseed Syrup					Côte de Blaye				
Boston Crab Meat				Escargots de Bourgogne		
Camembert Pierrot				Filo Mix					
Carnarvon Tigers				Flotemysost					
Chai							Geitost						
Chang							Genen Shouyu				
Chartreuse verte				Gnocchi di nonna Alice		
Chef Anton's Cajun Seasoning	Gorgonzola Telino			
Chef Anton's Gumbo Mix			Grandma's Boysenberry Spread
----							----						
Table: First 20 product names, sorted.

So how can this be an index? The answer is that this isn't actually the index. The link expression above is actually the _index definition_, this determines _what_ will be indexed (as well as exactly how, but we'll touch on that later). How does that work?

Let us look at Listing 6.1, this is the external representation of the index, but internally, we add need to track where the details came from so the end result is:

	from product in docs.Products
	select new { product.Name, **product.__document_id** }

The output of the index definition is a list of objects with a `Name` and a `__document_id` property. But what can we do with this? 

> The following isn't actually how this work in RavenDB, we'll get to the full details of that in a bit. This is an attempt to explain how RavenDB works by simplifying things as much as possible.

Now that we have the data to be indexed, we can actually put this in the index. From a logical perspective, Listing 6.2 shows what is going on after we have the index

```{caption="{Logical view of storing index entries in the index}" .cs}
var index = new Dictionary<string, string>(); // name --> doc id
foreach(var indexEntry in results)
	index[indexEntry.Name] = indexEntry.__document_id;
```

And queries now become a simple issue of reading through the index and then sending the results back, as shown in Listing 6.3.

```{caption="{Logical view of querying the index}" .cs}
// query for Name = Chang

var docId = index["Chang"]
return LoadDocument(docId);
```

Again, this isn't actually how it works, but it is a simple way of thinking about this.	And right now I want you to understand the general concept, rather than the actual details.

> **The `__document_id` property**
>
> The __document_id` is a reserved property named in RavenDB, it maps to the document id of the document, regardless of the client side convention. 

So, we use a LINQ expression to select the fields to index from our documents. We also add the relevant document id to the output, and then we put all of those details in an index. When we query, we use the index to figure out what is the actual document id that match the query, and then we load the document (or documents) from storage by id, and send it to the client.

For the rest of this chapter (and in general), we'll use the following terminology:

* **Indexing function** - the LINQ expression (such as the one in Listing 6.1) used to project the fields to be indexed from the documents.
* **Index entry** - the output of the indexing function. A single document can output zero or more index entries.
* **Indexing run** - the execution of all the indexes on a batch of documents. 

## Incremental indexing

By now, you have almost all the pieces you need to understand how RavenDB indexing works. In Chapter 4, we discussed [etags](#etags). An etag is just an ever increasing number that changes whenever a document changes. Because a RavenDB database can contain a _lot_ of documents, it isn't practical to run the indexing function over the entire data set every time. Instead, we do incremental indexing, and we do that using the etag. Listing 6.4 shows a simplified version of how indexing works.

```{caption="{Highly simplified indexing process}" .cs}
while (databaseIsRunning) {
	var lastDocEtag = GetLatestEtagForAllDocuments();
	var lastIndexEtag = GetLastIndexedEtagFor("Products/ByName");

	if(lastDocEtag == lastIndexEtag) { 
		// index is up to date
		WaitForDocumentsToChange();
		continue;
	}
	
	var docsToIndex = LoadDocumentsAfter(lastIndexEtag)
		.Take(autoTuner.BatchSize);
	for(var indexEntry in indexingFunc(docsToIndex)) {
		StoreInIndex(indexEntry);
	}
	SetLastIndexEtag("Products/ByName", docsToIndex.Last().Etag);
}
```

I'll repeat again that Listing 6.4 shows the _conceptual_ model, the actual working of this is very different. But the overall process is similar in intention if not in practice.

Indexing works by pulling a batch of documents from the document storage, applying the indexing function to them, and then writing the index entries to the index. We update the last indexed etag, and repeat the whole process again. When we run out of documents to index, we wait until a document is updated or changed, and the whole process starts anew. 

This means that when we index a batch of documents, we just need to update the index with their changes, no need to do all the work from scratch. You can also see in the code that we are processing the documents in batches (which are auto tuned for best performance). Even though the code in Listing 6.4 is far away from how it actually works, it should give you a good idea about the overall process.

## The indexing process

In relational databases, indexes are computed as part of the same write transaction. That leads to an interesting tradeoff. If you don't have the right indexes, you are falling back to a table scan, and all the performance degradation that comes with that. So you want your indexes to cover all the columns you are querying. But the more indexes you have, the slower writes become.

It ends up being up to the DBA, who need to make a judgment call. And often the DBA need to make that judgment call without a lot of information. The decision need to be made upfront, before the DBA has any actual performance numbers (because the application hasn't been created yet). With RavenDB, we chose a different approach.

Instead of executing the indexes as part of the write transactions, we run them as a background task. You can see a hint of that in Listing 6.4. This code (or rather, its conceptual cousin) is always running in the background, and whenever there is a change in the documents, the indexing function is run on the new or updated documents.

This has some interesting implications. The most obvious one is that there is an inherit race condition between updating a document and the indexes catching up with that update. Usually, the time between a document being updated and the relevant indexes being updated is measured in milliseconds, usually between 15 ms to 25 ms. 

> **Staleness in the real world**
> 
> At first sight, the idea of a query that may not be fully up to date sounds scary. But in practice, this is how we almost always work in the real world. The trivial counter example that I keep getting thrown in my face is financial transactions.
> 
> "Of course that you need full consistency for everything financial", they tell me. Try this, call you bank and ask them how much money you have in your account. The answer you'll get is going to be some variant of: "As of last business day, you had... ”.
> 
> Or let us take a pure software example, if you create a new bug, does it matter if your manager sees it right away, or wait an additional 25 ms to get it? This design choice was made explicitly, and it has quite a lot of benefits to it (detailed below).
>
> One very important factor to note is that RavenDB will always _tell_ you if you are getting potentially stale results, but more on that later.

The other implications of this design decision is that you the kind of promise the RavenDB database engine is drastically different than the kind of promises a relational database engine will give. A relational database will promise you that you'll have a fully consistent view of the universe. The problem with that is that it is very costly to actually do this. That is why relational databases has the concept of transaction isolation levels, and why very few of them opt to default to a high isolation level.

It is just too costly to do so. In order to keep its promise, the relational engine has to take locks, and do a lot of extra work to isolate different transactions from each other. The more transactions you have, the higher the cost. Until at a certain point, the relational database is overload and it will throw its hands up in the air and go sit in the corner while it is having a funk.

Your application, in the meantime, will start erroring (if you are lucky) or just hang, waiting for the relational database to respond.

With RavenDB, you get a different kind of promise. RavenDB will promise to:

* Give your immediate results based on what we currently have in the index.
* If the current state of the index isn't up to date, RavenDB will tell you so, including how up to date the index is.
* RavenDB will make its best to reduce the indexing latency.
* You have the option to explicitly wait for the results to become non stale.

> **Documents are always consistent**
>
> RavenDB uses the terms stale and non-stale to refer to out of date indexes. This is done intentionally, because consistency is always maintained. 
> 
> Listing 6.3 showed how queries work, from a logical perspective. We first consult the index to find a match for the query we are executing. Once we have the match, we have the relevant document id. Using that document id, we go to the document storage and load that document by id.
>
> The RavenDB's document storage subsystem is fully consistent^[For the database nerds, which I assume that you are if you are reading this book, the document storage subsystem implements Snapshot Isolation and optimistic write locks.], so you are always getting the latest committed version of the document.

Why is it important that RavenDB has a different set of promises than a relational database? 

Because by making a different set of promises, we have opened ourselves to a great deal of optimization opportunities. Here are just a few of those that are implemented in RavenDB.

### Throughput vs. Latency

I/O rates is usually the most expensive part of indexing. And it doesn't really matter if we are indexing a single document or a hundred, the base I/O cost of an indexing run is high enough to overshadow all other costs. Because of that, RavenDB utilizes several strategies when it comes to indexing. 

Under light load, RavenDB uses a low latency / low throughput strategy. Documents will be indexed as soon as possible, and while the I/O cost of that can be high, it doesn't matter, because we would don't have enough load to saturate the system. But when the load gets higher, RavenDB automatically switches to a different strategy. The high latency / high throughput strategy. Under those conditions, we are going to run fewer indexing runs, but each indexing run will have more documents that need to be updated. This allows us to amortize the I/O cost of indexing over a large set of documents, resulting in a greater efficiency all around.

> **What is with all the implementation details?**
> 
> You don't really need to know all those details. And even though I'm going over the details, I'm still leaving a lot of stuff out. 
> We are constantly tweaking this part of RavenDB in attempt to achieve higher performance and better throughput, so the details are subject to change.
> 
> But it is good to have a proper understanding of at least the kind of challenges that we have to go through, and the overall strategy to handle them. It can help you understand why RavenDB behave in a certain way in specific situations.

During indexing, we have to balance a fair number of variables to try to get to an optimum result. Indexing uses a lot of memory, we need to have the source documents to index, the actual output from the indexing function, generating the index itself, etc. Indexing is also a compute intensive operation, especially if you are using spatial indexing or require suggestions support. Indexing use a lot of I/O, because it needs to read the source documents, and write the index entries to disk.

> **Indexing scenarios**
>
> There are two common scenarios that pop up when talking about indexing. The new index mode and the steady state mode. In the new index mode, we have a new index defined, which need to index the entire data set. With large data sets, that can take a while.
> 
> The steady set mode is the usual way RavenDB runs, when most of the data is already indexed, and we only have to work on indexing the new/updated documents as they are written to the database. There are different optimizations for each scenario, and the interesting thing happen when we are actually creating a new index at the same time as we have existing indexes and a steady rate of writes to the database.
>
> In other words, a typical production setting, especially since we can expect indexes to be introduce to the system on a fairly regular basis in production (by the query optimizer, for example). Unlike many relational databases, introducing a new index to a production system result in no locks, and it is perfectly fine to do so. There is a cost in the actual indexing, but RavenDB knows how to manage that to avoid using too much.
>
> The level of trust we have in this system is so high that we let an automated component make indexing decisions on the fly, to self-optimize your database.

The indexing code in RavenDB need to balance competing requirements between all those resources, and at the same time, make sure that we aren't overwhelming the machine we are running on. The other side of that is that if we have a lot of resources on the machine (many cores, lot of memory, SSD drives), we want to make the best use of those resources that we can. Let me see if I can explain how we try to maximize resource utilization without using _too_ much.

### Parallel indexing 

Let us assume that you have a database with a million documents in it, and you just created ten new indexes. The server machine has 4 cores and 8 GB of memory. What would happen now? Each of the indexes need to go over the entire data set. One way to handle this is to spin up a thread for each index, point it at the documents, and let it run. This has a lot of issues. To start with, each of the indexes are going to need the same source data (the documents), so just running each independently will result in a lot of duplicated I/O and memory usage. It also turn out to be problematic because we might actually generate so much CPU work that we won't have the time to process requests, if we have ten threads doing compute intensive work.

The actual indexing process in RavenDB is split into runs. On each run, we load a batch of documents, then select a number of indexes^[the exact number depend on your configuration and license, but on the system we specified, it will be 4 - 8, usually.] and let them run on that batch. When those indexes are done, it will select the next set of indexes to run, and so on until we are done with all the indexes that are relevant for this batch.

> **Parallelism at the single index level**
>
> RavenDB also parallelize work at the single index level. A single index that need to process a large number of documents will also execute the indexing work in parallel. The idea is maximize parallelism at both the single index level and among all indexes.

If there are still documents to be indexed, we'll then fetch the next batch of indexes, and go through the process again. The reasoning behind limiting the number of concurrent index executions is that each index is going to be doing a lot of compute intensive work (indexing) as well as use up memory. By limiting the number of indexes that execute concurrently we can reduce the overall indexing cost.

### Auto tuning batches

We mentioned batches a few times, but let us talk about what those batches actually _are_. At the simplest level, a batch is just a collection of documents, just "give me the next 128 documents after this etag by etag order". Because we feed batches into the indexing process, the actual size of the batch is quite important. The biggest the batch, the more work the indexes will do, and the longer they will take to run. But because there are fixed I/O costs per batch, the bigger the batch, the less time we take _per document_, up to a point.

A question come up then, how do we decide what the batch size would be? This seems to be a typical configuration value that we'll let the administrator decide. But that is a pretty sensitive option, with regards to the system performance, and we don't want to have the administrator on call to start modifying this configuration value in production if things change. That is why RavenDB doesn't have a configuration value for this property. Instead, it has a configuration _range_ (min and max values). The RavenDB engine will determine the optimal batch size within this range automatically.

When there isn't a lot of work to do, the batch sizes are going to be small, favoring low latency (and low throughput). But when we are facing a high write situation, or when we have to index a lot of data (such as when we have a new index on a large database), RavenDB will note that the small batch sizes aren't enough to process the data quickly and start increasing the batch size. This is controlled by many factors (current indexing time and available memory, among many), to avoid creating a batch size that is _too_ large, but in practice, this works very well.

When we have a large number of items to index, we will slowly move to a larger batch size and process more items per batch. This is the high throughput (but high latency) indexing strategy that we talked about. When the load goes down, we'll decrease the batch size to its initial level. This seemingly simple change has dramatic implications on the way RavenDB can handle spikes in traffic. We'll automatically (and transparently) adjust to the new system conditions. That is much nicer than waking your administrators at 3 AM.

### What gets indexed?

This is an interesting question, and it often trips people up. Let us assume that we have the two indexes showing in Listing 6.5.

```{caption="{A couple of index definitions}" .cs}
//users/ByNameAndEmail
from user in docs.Users
select new { user.Name, user.Email }

//orders/ByOrderIdAndCustomerEmail
from order in docs.Orders
select new { order.OrderId, order.Customer.Email }
```

The first index users by name and email, and the second allow us to query on orders by the order id or the customer's email. What would happen when we create a new `Order` document?

Well, we need to execute all the relevant indexes on this, and at first glance, it will appear that we only need to index this document using the second index. The problem is that we don't know this yet. More to the point, we don't have a good way of _knowing_ that. We determine if an index needs to be indexed or not by checking its last indexed etag and comparing that to the latest document etag. That information doesn't take into account the details of which collection belongs to.

Because of that, all indexes need to process all documents, if only to verify that they don't care for those. At least, that is how it works in theory.

> Remember, this is a deep implementation details discussion. Please understand that the following details are just that, implementation details, and are subject to change in the future. 

In practice, we take quite a bit of advantage on the nature of RavenDB to optimize how this works. We still need to read the documents, but we can figure out ahead of time that a certain document isn't a match for a specific index, so we can avoid even giving the document to the index. That means that we can just update the last indexed etag of that index past any document that doesn't match the collections that this index operates on.

That works quite efficiently in reducing the amount of work required when we are indexing new and updated documents only, but it gets more complex when we need to deal with a new index creation. 

### Introducing a new index

I mentioned already that in RavenDB, the process of adding a new index is both expected and streamlined. While this is indeed the case, it does not mean that it is a _simple_ process. A new index requires that we'll index all the previous documents in the database. And we don't know, at this time, what collections they actually belong to. So if we have ten million documents in the database and we introduce a new index, we'll need to read them all, send the matching documents to the index, and discard the rest. That is the case even if your index only cover a collection that has a mere hundred documents.

As you can imagine, this is quite expensive, and not something that we are very willing to do. Because of that, there are several optimizations that are applied during this process. The first of which is to use the system index `Raven/DocumentsByEntityName` to find out exactly how many documents we have to cover. If the number is small (under 131,072 documents, by default), we'll just load all the relevant documents and index them on the spot. 
This gives us a great advantage when creating new indexes on small collections, because we can catch up very quickly.

> **What happen when you have multiple new indexes?**
>
> So far, we talked about the scenario where we have just a single new index, but it is pretty common to have multiple new indexes created at roughly the same time.
>
> This can happen during a new deployment, when you created several new indexes. RavenDB is aware of this, and it will consider indexes that are roughly in the same position with regards to indexing to be part of the same group. 
>
> In particular, the way it is structured, creating multiple new indexes in a short amount of time will tend to group them into their own group and index all of them together.

However, that doesn't really help us in the case of bigger collections. What happens then? At this point, one of two strategies comes into play, depending on the exact situation involved. If there aren't enough resources, the database will split the work between the new index and the existing index. So the new index will get a chance to run and index a batch of documents, then the existing indexes will have a chance to run over any new documents that came in, etc.
RavenDB is biased in this situation toward the existing indexes, because we don't want to stall them too much. That might mean that the new index will take time to build completely, but that isn't generally an issue, it is a new index, and expected to take some time.

If there is a wealth of resources to exploit, however, RavenDB will chose a different strategy. It will create a dedicated indexing task that will run in the background, separate from the normal indexing process and in parallel to it. This indexing process will try to get as many documents index for the new index as it possibly can as fast as it can. This generally require more resources (memory, CPU & I/O), so even though this is the preferred strategy, we can't always apply it.

At any rate, introducing a new index is a well-oiled process by now, even on large database, that it is a safe enough process that we let an automated system decide when we need a new index. 

### I/O Considerations

I/O is by far the most costly part of the indexing effort, and the hardest to optimize. This is because RavenDB can run on systems that have persistent RAM disks (so reading from disk is effectively free) to virtual disks whose data is actually fetched over the network (so I/O latency is _very_ high). Note that this applies for both reads and writes. Indexing need to read (potentially a large amount) of documents so it can actually index them, and it need to write (much smaller) amount of data to the index.

In order to best utilize the system resources, we have a component called the prefetcher queue^[This is used by the indexing and the replication processes.] that is responsible for supplying the indexes with the next batch. We do that using several ways. In the steady state mode, whenever a new document is added / updated, we also register it in the prefetchers. That means that normally, indexing does need to hit the disk at all, it can index completely from memory.

For indexes that need to access data that is already on disk, we apply a different optimization. Whenever the prefetcher is done handing out a batch, it start an asynchronous process to load the next batch to memory. That way, when the indexes are done and want the next batch, it is already ready for them and can hand the next batch immediately.

The actual behavior is pretty complex, because we don't want to load so much data so we won't have enough memory to do the actual indexing, and document sizes aren't fixed. We also need to take into account the I/O speeds that we can get as well as the document sizes. Because batch size can change, it is possible to get a batch size that is large enough that it takes so long to fetch that the optimization is useless. This is especially the case with virtual network hardware (where high latency is the rule, rather than the exception).

Because of that, when loading data from the disk we are actually limiting ourselves on multiple fronts. Count of indexes, total size read and the time to read from disk. If we hit any of those limitations, we immediately stop the reading process and return with whatever data we already have. Otherwise, we might be stuck waiting for all the records to load, while we can use the time to also do indexing.

Because the prefetcher will fetch the next batch in the background, it is more efficient to have a smaller batch and hand it for indexing, while we are fetching the next batch. Otherwise, we'll spend a lot of time in I/O, without using the CPU resources for indexing.

The other side of I/O is writing the data. Usually, we write a lot less data than we read for indexing, so that is a far less troublesome area. But here, too, we have applied optimizations. When writing to the index, we always write directly to memory first and firstmost. And at the end of the index run, we'll _not_ be writing those changes to disk. Going to disk is expensive, so we're trying to avoid it if possible. 

So, when do we write to disk? When one of the following happen:

* When the amount of memory used cross a certain threshold. Currently this is 5 MB^[This is configurable via the Raven/Indexing/FlushIndexToDiskSizeInMb setting], so after the index in memory hit that size, we'll flush this to disk. 
* When there are no more documents to index and there is nothing else to do.
* When a certain time threshold has passed without flushing to disk.

This allows us to only go to the disk for writes when we really have to. In the meantime, we are still able to give you full access to the indexed results directly from memory. However, that does raise an interesting question. If we store things in memory, what happen in the presence of failure?

## Index safeties

RavenDB is an ACID database. That means that putting data into RavenDB you are ensured that the only way to lose this data is if you physically take a hammer to the disk drive. The same isn't quite true to indexes. Indexes are updated in the background, and we do a lot of work to ensure that we give you both fast indexing times and fast query times. That means that a lot of the time, we operate on in memory data.

In other words, as soon as there is a failure, all this data goes away. Well, not really. Remember, the data is only in memory up to a point, at which point it get saved to disk. So at worst, if we have a hard crash, we lose _some_ indexing data, but we check this on startup, and that only means that we'll have to re-index the last few documents that hasn't been persisted to disk yet. So we are good. Or are we?

RavenDB uses Lucene^[To be rather more exact, we use [Lucene.NET](http://lucenenet.apache.org/).] as its indexing format, that gives us a lot of power, because Lucene is a very powerful library. Unfortunately, it is anything but simple to work with operationally, I'll touch on that in the next section, but the important fact is that Lucene doesn't guarantee that its data will be safely flushed to disk even if it actually does write to disk^[To the database nerds, the different is the lack of call to fsync() or its moral equivalent when finishing writing. A crash can still cause the data written to the file to be lost].

RavenDB take a proactive approach to handle that. On startup, we ensure that the index is healthy, and if needed, we'll reset it to a previous point (or entirely) to make sure that we don't lose data from the index. This is usually only required after a hard machine failure, though. We have run RavenDB through many simulations to make sure that this is the case. In one particular test case, we managed to find a bug after 80 consecutive hard crashes (pulling the power cord from the machine)^[I'll also take this opportunity to thank Tobias Grimm, who was great help finding those kind of issues].

In short, documents stored in RavenDB are guaranteed to always be there, even if you start pulling power cords and crashing systems. Index entries in the index don't have this promise, but we'll ensure that we fill any missing pieces (by simply re-running the index again over the source data) if something really bad happened. We keep to our respective promises on each side. Documents are safe and consistent, indexes are potentially stale and eventually consistent.

## Lucene

I mentioned earlier that we are using Lucene to store our indexes. But what is it? Lucene is a library to create an inverted index. It is mostly used for full text searching and is the backbone of many search systems that you routinely use. For example, Twitter and Facebook are using Lucene, and so does pretty much anyone else. It has got to the point that other products in the same area always compare themselves to Lucene.

Now, Lucene has a pretty bad reputation^[It is fairly involved to run, from operations point of view.], but it is the de facto industry standard for searching. So it isn't surprising that RavenDB is using it, and doing quite well with it. We'll get to the details about how to use Lucene's capabilities in RavenDB on the next chapter, now I would like to talk about how we are actually using Lucene in RavenDB.

I mentioned that successfully running Lucene in production is somewhat of a hassle for operations. This has to do with several reasons:

* Lucene needs to occasionally compact its files (a process called merge). Controlling how and when this is done is key for achieving good performance when you have a lot of indexing activities.
* Lucene doesn't do any sort of verifiable writes. If the machine crash midway through, you are open for index corruption. 
* Lucene doesn't have any facility for online backup process.
* Optimal indexing and querying speeds depend a lot on the options you use and the exact process in which you work.

All of that require quite a bit of expertise. We've talked about how RavenDB achieve safety with indexes in the previous section. The others issues are also handled for you by RavenDB. I know that the previous list can make Lucene look scary, but I think that Lucene is a great library, and it is a great solution for handling search.

## Transformations on the indexing function

So far, we have gone through the details on how RavenDB indexes work (transforming a set of input document into Lucene index entries) and we spent a considerable amount of time diving into the details behind the actual indexing process itself. Now I want to focus primarily on what RavenDB with the index definitions you create. Let us look at Listing 6.6 and Listing 6.7, which show a simple index definition and what RavenDB does with it (respectively).

```{caption="{A simple index definition}" .cs}
// users/ByNameAndEmail
from user in docs.Users
select new { user.Name, user.Email }
```
What would happen when we create such an index in RavenDB? The RavenDB engine will transform the simple index definition in Listing 6.6 into the class shown in Listing 6.7. You can look at that and see the actual indexing work that is being done with RavenDB^[You can always get the source for each index definition by going to the following URL: http://localhost:8080/databases/Northwind/users/ByNameAndEmail?source=yes (naturally, you'll need to change the host, database and index names according to your own system).].

```{caption="{The generated index class in RavenDB}" .cs}
public class Index_users_ByNameAndEmail : 
	Raven.Database.Linq.AbstractViewGenerator
{
	public Index_users_ByNameAndEmail()
	{
		this.ViewText = @"
from user in docs.Users
select new { user.Name, user.Email } ";
		
		this.ForEntityNames.Add("Users");

		this.AddMapDefinition(docs => 
			from user in ((IEnumerable<dynamic>)docs)
			where string.Equals(
					user["@metadata"]["Raven-Entity-Name"], "Users", 
					System.StringComparison.InvariantCultureIgnoreCase)
			select new {
				user.Name,
				user.Email,
				__document_id = user.__document_id
			});

		this.AddField("__document_id");
		this.AddField("Name");
		this.AddField("Email");
		this.AddQueryParameterForMap("__document_id");
		this.AddQueryParameterForMap("Name");
		this.AddQueryParameterForMap("Email");
		this.AddQueryParameterForReduce("__document_id");
		this.AddQueryParameterForReduce("Name");
		this.AddQueryParameterForReduce("Email");
	}
}
```

All indexes inherit from the `AbstractViewGenerator` class. And the actual indexing work is done in the lambda passed to the `AddMapDefinition` call. You can see how we changed the index definition. The `docs.Users` call, which looks like a collection reference was changed to the more accurate where statement, which filter unwanted items from different collections. You can also see that in addition to the properties that we have for indexing, we also include the `__document_id` property.

Note that we keep the original index definition in the `ViewText` property (mostly for debug purposes), and that we keep track of the entity names each index covers. The latter is very important for optimizations, since we can make decisions based on this information (which documents we can _not_ send to this index).

> **The RavenDB Indexing Language**
> 
> On the surface, it looks like the indexing language RavenDB is using is C# LINQ expressions. And that is true, up to a point. In practice, we have taken the C# language prisoner, and made it jump through many hoops to make our indexing story easy and seamless.
>
> The result isn't actually plain C#, for example, there are no nulls. Instead, we use the Null Object pattern to avoid dealing with NullReferenceExceptions. Another change is that the language we use isn't strongly typed, and won't error on missing members.
>
> All of that said, you can actually debug a RavenDB index in Visual Studio, because however much we twist the language's arm, we end up compiling to C#.

The rest of the calls (`AddField`, `AddQueryParameterForReduce`, `AddQueryParameterForMap`) are most there for book keeping purposes, and are used by the query optimizer to decide if an index should get to handle a specific query.

## Error handling

We try very hard to ensure that an index can't actually generate errors, but in the real world, it isn't actually an attainable goal. So the question now becomes, what is going to happen when an index runs into an error? Those can be divided into several parts.

The indexing function can run into trouble. The easiest way to reproduce that is to have a division in the indexing function, and have the denominator set to zero. That obviously cause a DivideByZeroException. What happens then? The indexing process will terminate the indexing of the document that caused this issue, and an error will be logged. You can see the indexing errors in the studio and in the index statistics. 

Along with the actual error message, you'll have the faulting index and the document that caused all that problem. In general, errors in indexes aren't a problem, but because an error stops a document from being index (only by the index that actually caused the error, mind) it can be hard to understand why. A query on the index won't fail if some documents failed to be indexed, you need to explicitly check the stats page (or the database statistics) to see the actual error.

If a large percentage of the documents are erroring (over 15%, once we are past some initial number of documents), however, we'll decree that index as faulty. At that point, it will not be active any longer and won't take part in indexing. Any queries made to the index will result in an exception being thrown. You'll need to fix the index definition so it won't throw so many errors for it to resume standard operations.

Another type of indexing errors relates to actual problems in indexing. For example, the indexing disk might be full. This will cause the indexing process to fail, although that wouldn't count against the 15% fail quota for the index. You'll be able to see the warning about those failures in the log.

## What about deletes?

So far, we talked a lot about how indexing works for new or updated documents. But how does the indexes work when we _delete_ documents? The short answer is that this is a much more complicated process, and it was quite annoying to have to deal with it.
The basic process goes like this: Whenever a document is deleted, we check all the indexes for those who would cover this particular document. We then generate a `RemoveFromIndexTask` background task for each of those indexes. We save that background task in the same transaction as the document deletion. The indexing process will check for any pending tasks as part of its process, and it will load and execute those tasks.

In this case, the work this task will do is to remove the relevant documents from the indexes in question. The process is quite optimized, and we'll merge similar tasks into a single execution, to reduce the overall cost. That said, mass deletion, in particular, is a costly operation in RavenDB.

Note that as soon as the document is actually deleted from the document store, we won't be returning it from any queries, and the purpose of the `RemoveFromIndexTask` is to clean up the indexes more than anything else.  

## Indexing priorities

Users frequently request some better ways to control the indexing process priorities. To decide that a particular index is very important, and should be given the first priority above all other indexes. While this seems to be a reasonable request, it does open up a lot of very complex issues.
In particular, how do you prevent starvation of the other indexes, if the very important index is running all the time?

So instead of implementing a `ThisIsVeryImportantIndex` flag, we switched things around and allow you to indicate that a particular index isn't that important. The following indexing priorities are supported:

* Normal - The default, execute this index as fast as possible.
* Idle - Only execute this index when there is no other work to be done.
* Abandoned - Only execute this index when there is no other work to be done, and there hasn't been any work for a while, and it has been a long time since we last ran this.
* Disabled - Don't index at all.
* Error - This index has too many errors and has failed.

`Idle` indexing will happen if RavenDB don't have anything else. `Abandoned` is very similar to `Idle`, but it won't trigger even if we have nothing to do. It will only trigger if we didn't have anything to do for a _long_ while. The expectation is that abandoned indexes will run whenever you have a long idle period. For example, at night or over the weekends.

> **Why not have a Priority level?**
> 
> Any priority scheme has to deal with starvation issues. And while it seems like a technical detail, there is a big difference in the expectation if you have an index set to idle and another index set to normal than you have one index set to normal and the other to priority. 
> 
> In the first case, it is easy to understand that the index won't run as long as the normal index has work to do. In the second case, you probably want both to run, but the priority to run more often or with higher frequency.
> The problem with starvation prevention is that you have to punish the important index at some point, by blocking it and running the other indexes. At which point, they have a lot of work to do, so they can take a long time to run, and you defeated the whole point of priorities.
> 
> It might be a semantic difference, but I feel that this way clearly states what is going to happen, and reduce surprises down the road.

Note that the query optimizer will play with those options for the auto indexes that it creates, but it won't interfere with indexes that were created explicitly by the user.

## Summary

We've gone over the details of how RavenDB indexing actually _work_. Hopefully not in a mind numbing detail. Those details are not important during your work with RavenDB, all of that is very well hidden under the covers, but it is good to know how RavenDB will respond to changing conditions.

We started talking about the logical view of indexing in RavenDB. How an indexing function output index entries that will be stored in a Lucene index, and how queries will go against that index to find the matching document ids, which will be pulled from document storage. We then talked about incremental indexing and the conceptual process of how RavenDB actually index documents.

From the conceptual level, we moved to the actual implementation details, including the set of tradeoffs that we have to make in indexing between I/O, CPU and memory usage. We looked at how we deal with each of those issues. Optimizing I/O by prefetching documents and batching writes. Optimizing memory by auto tuning the batch size and optimizing CPU usage by parallelizing work (but not too much).

We also talked about what actually gets indexed, and how we optimize things so an index doesn't have to go through all documents, only those relevant for it. Then we talked about the new index creation strategies, how we try to make sure that this is as efficient as possible while still letting the system operate normally. 

We got to talking a bit about Lucene, how we actually manage the index and safe guard from corruption and handle recovery. In particular by managing the state of the index outside of Lucene, but by checking to see the recovered state in case of a crash.

We concluded the chapter by talking about the actual code that gets run as part of the index, error handling and recovery during indexing and the details of index priorities and why they are setup the way they are.

I hope that this peek behind the curtain doesn't make you lose any faith in the magical properties of RavenDB, pay no attention to the man behind the screen, as the Wizard said. Even after knowing how everything work, it still seems magical to me. And one of the most magical features in RavenDB is the topic of the next chapter, how RavenDB allows ad-hoc queries by using automatic indexing and the query optimizer.
